{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac0e98d-c376-4edd-8c85-07a9da7fecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from model_function_ss_speaker import model_fitting_sp\n",
    "from model_function_ss_addressee import model_fitting_ad\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "889c5334-0e05-41b1-a01e-9e11cb8bba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def book_read(book_name):\n",
    "    \n",
    "        book = pd.read_csv('predicted_books/baseline/'+book_name+'baselinepredicted.csv')\n",
    "    \n",
    "        # make addressees lists\n",
    "    \n",
    "        for i in book.index:\n",
    "    \n",
    "            if book.at[i,'dialogue'] != 'NO QUOTE':\n",
    "    \n",
    "                list_ad = []\n",
    "    \n",
    "                addressee = book.at[i,'addressee']\n",
    "    \n",
    "                for j in range(len(addressee)):\n",
    "    \n",
    "                    if addressee[j] == '\\'':\n",
    "    \n",
    "                        word = ''\n",
    "    \n",
    "                        for k in range(j+1,len(addressee)):\n",
    "    \n",
    "                            if (addressee[k] != '\\''):\n",
    "    \n",
    "                                word = word + addressee[k]\n",
    "    \n",
    "                            else:\n",
    "                    \n",
    "                                break\n",
    "                    \n",
    "            \n",
    "                        list_ad.append(word)\n",
    "    \n",
    "    \n",
    "                while ', ' in list_ad:\n",
    "                        \n",
    "                    list_ad.remove(', ')\n",
    "    \n",
    "                while ']' in list_ad:\n",
    "                        \n",
    "                    list_ad.remove(']')\n",
    "                    \n",
    "\n",
    "\n",
    "                # As the focus of ML based addressee attribution is to only predict single addressees, multi addressee entries should be np.nan\n",
    "                \n",
    "                if len(list_ad) == 1: # single addressee\n",
    "                \n",
    "                    book.at[i,'addressee'] = list_ad[0]\n",
    "\n",
    "                else: # multi addresseees\n",
    "\n",
    "                    book.at[i,'addressee'] = np.nan\n",
    "\n",
    "        return book\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b5d1f46-be1e-417e-9061-a92fe4f24c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Novel Names to be checked\n",
    "\n",
    "Novel_names = []\n",
    "\n",
    "with open('pdnc_dataset/PDNC-Novel-index.csv','r') as file:\n",
    "\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    for i in reader:\n",
    "\n",
    "        novel_name = \"\"\n",
    "\n",
    "        for j in i[1]:\n",
    "            if ((j != \" \") and (j != \"'\") and (j != \"-\")):\n",
    "                novel_name = novel_name + j\n",
    "\n",
    "        \n",
    "        Novel_names.append(novel_name)\n",
    "        \n",
    "    Novel_names.remove('NovelTitle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12112fea-82e1-42dd-9df6-5db9c4a1bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Accuracy table \n",
    "\n",
    "performance = [['Book_Name','Model','Speaker','Addressee','Full']]\n",
    "\n",
    "results_ML = pd.read_csv('results_ML.csv')\n",
    "results_BL = pd.read_csv('results_baseline.csv')\n",
    "\n",
    "speaker_sum_ML = 0\n",
    "addressee_sum_ML = 0\n",
    "full_sum_ML = 0\n",
    "\n",
    "speaker_sum_BL = 0\n",
    "addressee_sum_BL = 0\n",
    "full_sum_BL = 0\n",
    "\n",
    "\n",
    "for i in Novel_names:\n",
    "\n",
    "    # getting the results of each novel in the baseline algorithm\n",
    "\n",
    "    ML_speaker_accuracy = list(results_ML.loc[(results_ML['book_name'] == i)]['speaker_ac'])[0]\n",
    "\n",
    "    ML_addressee_accuracy = list(results_ML.loc[(results_ML['book_name'] == i)]['accuracy_ac'])[0]\n",
    "\n",
    "    ML_full_accuracy = list(results_ML.loc[(results_ML['book_name'] == i)]['full_ac'])[0]\n",
    "\n",
    "    BL_speaker_accuracy = list(results_BL[(results_BL['book_name'] == i)]['speaker_ac'])[0]\n",
    "\n",
    "    BL_addressee_accuracy = list(results_BL[(results_BL['book_name'] == i)]['accuracy_ac'])[0]\n",
    "\n",
    "    BL_full_accuracy = list(results_BL[(results_BL['book_name'] == i)]['full_ac'])[0]\n",
    "\n",
    "    performance.append([i,'ML',ML_speaker_accuracy,ML_addressee_accuracy,ML_full_accuracy])\n",
    "\n",
    "    performance.append([i,'BL',BL_speaker_accuracy,BL_addressee_accuracy,BL_full_accuracy])\n",
    "    \n",
    "\n",
    "    speaker_sum_ML = speaker_sum_ML + list(results_ML.loc[(results_ML['book_name'] == i)]['speaker_ac'])[0]\n",
    "\n",
    "    addressee_sum_ML = addressee_sum_ML + list(results_ML.loc[(results_ML['book_name'] == i)]['accuracy_ac'])[0]\n",
    "\n",
    "    full_sum_ML = full_sum_ML + list(results_ML.loc[(results_ML['book_name'] == i)]['full_ac'])[0]\n",
    "\n",
    "    speaker_sum_BL = speaker_sum_BL + list(results_BL[(results_BL['book_name'] == i)]['speaker_ac'])[0]\n",
    "\n",
    "    addressee_sum_BL = addressee_sum_BL + list(results_BL[(results_BL['book_name'] == i)]['accuracy_ac'])[0]\n",
    "\n",
    "    full_sum_BL = full_sum_BL + list(results_BL[(results_BL['book_name'] == i)]['full_ac'])[0]\n",
    "\n",
    "# averaging sums\n",
    "\n",
    "speaker_sum_ML = speaker_sum_ML / 13\n",
    "\n",
    "addressee_sum_ML = addressee_sum_ML / 13\n",
    "\n",
    "full_sum_ML = full_sum_ML / 13\n",
    "\n",
    "speaker_sum_BL = speaker_sum_BL / 13\n",
    "\n",
    "addressee_sum_BL = addressee_sum_BL / 13\n",
    "\n",
    "full_sum_BL = full_sum_BL / 13\n",
    "\n",
    "\n",
    "# writing to csv\n",
    "\n",
    "performance.append(['Average','Baseline',speaker_sum_BL,addressee_sum_BL,full_sum_BL])\n",
    "performance.append(['Average','ML',speaker_sum_ML,addressee_sum_ML,full_sum_ML])\n",
    "\n",
    "\n",
    "performance = pd.DataFrame(performance)\n",
    "\n",
    "performance.to_csv('Tables/final_accuracy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "722deb89-e176-4e8f-ad24-841f8508d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring speaker attribution performance per syntactic category \n",
    "\n",
    "\n",
    "performance = [['Model','Explicit','Anaphoric','Implicit']] # initialising list \n",
    "\n",
    "explicit_sum_BL= 0\n",
    "anaphoric_sum_BL = 0\n",
    "implicit_sum_BL = 0\n",
    "\n",
    "explicit_sum_ML = 0\n",
    "anaphoric_sum_ML = 0\n",
    "implicit_sum_ML = 0\n",
    "\n",
    "\n",
    "for i in Novel_names:\n",
    "\n",
    "    book_pred_BL = pd.read_csv('predicted_books/baseline/'+i+'baselinepredicted.csv') # predicted book \n",
    "    book_pred_ML = pd.read_csv('predicted_books/ML_Full/'+i+'MLFullpredicted.csv') # predicted book \n",
    "\n",
    "    book_real = pd.read_csv('annotated_books/'+i+'annotated.csv') # real book \n",
    "\n",
    "    # getting the filters (Baseline)\n",
    "\n",
    "    book_pred_exp_BL = book_pred_BL[book_pred_BL['syntactic'] == 'Explicit']\n",
    "    book_real_exp_BL = book_real[book_real['syntactic'] == 'Explicit']\n",
    "    book_pred_ana_BL = book_pred_BL[book_pred_BL['syntactic'] == 'Anaphoric']\n",
    "    book_real_ana_BL = book_real[book_real['syntactic'] == 'Anaphoric']\n",
    "    book_pred_imp_BL = book_pred_BL[book_pred_BL['syntactic'] == 'Implicit']\n",
    "    book_real_imp_BL = book_real[book_real['syntactic'] == 'Implicit']\n",
    "\n",
    "    # getting the filters (ML)\n",
    "\n",
    "    book_pred_exp_ML = book_pred_ML[book_pred_ML['syntactic'] == 'Explicit']\n",
    "    book_real_exp_ML = book_real[book_real['syntactic'] == 'Explicit']\n",
    "    book_pred_ana_ML = book_pred_ML[book_pred_ML['syntactic'] == 'Anaphoric']\n",
    "    book_real_ana_ML = book_real[book_real['syntactic'] == 'Anaphoric']\n",
    "    book_pred_imp_ML = book_pred_ML[book_pred_ML['syntactic'] == 'Implicit']\n",
    "    book_real_imp_ML = book_real[book_real['syntactic'] == 'Implicit']\n",
    "\n",
    "\n",
    "    # find accuracy for explicit\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for i in (book_pred_exp_BL.index): # same indices for pred and real\n",
    "\n",
    "        if (book_pred_exp_BL.at[i,'speaker'] == book_real_exp_BL.at[i,'speaker']):\n",
    "\n",
    "            count += 1\n",
    "\n",
    "    explicit_sum_BL += (count / len(book_pred_exp_ML.index))\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for i in (book_pred_exp_ML.index): # same indices for pred and real\n",
    "\n",
    "        if (book_pred_exp_ML.at[i,'speaker'] == book_real_exp_ML.at[i,'speaker']):\n",
    "\n",
    "            count += 1\n",
    "\n",
    "    explicit_sum_ML += (count / len(book_pred_exp_ML.index))\n",
    "\n",
    "\n",
    "    # find accuracy for anaphoric\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for i in (book_pred_ana_BL.index): # same indices for pred and real\n",
    "\n",
    "        if (book_pred_ana_BL.at[i,'speaker'] == book_real_ana_BL.at[i,'speaker']):\n",
    "\n",
    "            count += 1\n",
    "\n",
    "    anaphoric_sum_BL += (count / len(book_pred_ana_BL.index))\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for i in (book_pred_ana_ML.index): # same indices for pred and real\n",
    "\n",
    "        if (book_pred_ana_ML.at[i,'speaker'] == book_real_ana_ML.at[i,'speaker']):\n",
    "\n",
    "            count += 1\n",
    "\n",
    "    anaphoric_sum_ML += (count / len(book_pred_ana_ML.index))\n",
    "\n",
    "\n",
    "    # find accuracy for implicit\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for i in (book_pred_imp_BL.index): # same indices for pred and real\n",
    "\n",
    "        if (book_pred_imp_BL.at[i,'speaker'] == book_real_imp_BL.at[i,'speaker']):\n",
    "\n",
    "            count += 1\n",
    "            \n",
    "    implicit_sum_BL += (count / len(book_pred_imp_BL.index))\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for i in (book_pred_imp_ML.index): # same indices for pred and real\n",
    "\n",
    "        if (book_pred_imp_ML.at[i,'speaker'] == book_real_imp_ML.at[i,'speaker']):\n",
    "\n",
    "            count += 1\n",
    "            \n",
    "    implicit_sum_ML += (count / len(book_pred_imp_ML.index))\n",
    "\n",
    "\n",
    "# averaging up the sums\n",
    "\n",
    "explicit_sum_BL = explicit_sum_BL / 13\n",
    "anaphoric_sum_BL = anaphoric_sum_BL / 13\n",
    "implicit_sum_BL = implicit_sum_BL / 13\n",
    "\n",
    "explicit_sum_ML = explicit_sum_ML / 13\n",
    "anaphoric_sum_ML = anaphoric_sum_ML / 13\n",
    "implicit_sum_ML = implicit_sum_ML / 13\n",
    "\n",
    "\n",
    "\n",
    "performance.append(['baseline',explicit_sum_BL,anaphoric_sum_BL,implicit_sum_BL])\n",
    "performance.append(['ML',explicit_sum_ML,anaphoric_sum_ML,implicit_sum_ML])\n",
    "\n",
    "\n",
    "performance = pd.DataFrame(performance)\n",
    "\n",
    "performance.to_csv('Tables/syntactic_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a9899f66-09d6-4d25-8148-928c0730d8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing book AlicesAdventuresinWonderland\n",
      "doing book AnneOfGreenGables\n",
      "doing book Emma\n",
      "doing book NorthangerAbbey\n",
      "doing book Persuasion\n",
      "doing book PrideandPrejudice\n",
      "doing book SenseandSensibility\n",
      "doing book TheAgeofInnocence\n",
      "doing book TheAwakening\n",
      "doing book TheInvisibleMan\n",
      "doing book TheManWhoWasThursday\n",
      "doing book ThePictureOfDorianGray\n",
      "doing book TheSignoftheFour\n"
     ]
    }
   ],
   "source": [
    "# A test to see if vocatives are being predicted as addressees (Table 8)\n",
    "\n",
    "count_vocative = 0\n",
    "\n",
    "count_vocative_found_BL = 0\n",
    "count_vocative_found_ML = 0\n",
    "count_vocative_found_ML_SA = 0\n",
    "\n",
    "count_quotes = 0\n",
    "\n",
    "for book_name in Novel_names:\n",
    "\n",
    "    print(f'doing book {book_name}')\n",
    "\n",
    "    character_info = pd.read_csv('pdnc_dataset/data/'+ book_name +'/character_info.csv')\n",
    "    \n",
    "    Characters = character_info['Main Name']\n",
    "    Characters = list(Characters)\n",
    "    \n",
    "    Aliases = []\n",
    "    \n",
    "    \n",
    "    for i in character_info.index:\n",
    "        new_list = []\n",
    "        for j in range(len(character_info.at[i,'Aliases'])):\n",
    "            string = character_info.at[i,'Aliases']\n",
    "            if string[j] == '\\'':\n",
    "                new = ''\n",
    "                index = j+1\n",
    "                while (string[index] != '\\'' and index < (len(string)-1)):\n",
    "                    new = new + string[index]\n",
    "                    index += 1\n",
    "                new_list.append(new)\n",
    "    \n",
    "        # removing ', ' and '' terms\n",
    "    \n",
    "        for j in new_list:\n",
    "            if (j == ', ' or j == ''):\n",
    "                new_list.remove(j)\n",
    "        \n",
    "        Aliases.append(new_list)\n",
    "\n",
    "\n",
    "    # getting real book / all other predicted books\n",
    "\n",
    "    book_real = pd.read_csv('annotated_books/' + book_name + 'annotated.csv')\n",
    "    \n",
    "    book_predicted_BL = book_read(book_name)\n",
    "    book_predicted_ML = pd.read_csv('predicted_books/ML_Full/' + book_name + 'MLFullpredicted.csv')\n",
    "    book_predicted_ML_SA = pd.read_csv('predicted_books/ML_SA/' + book_name + 'ML_SApredicted.csv')\n",
    "\n",
    "\n",
    "    # searching for quotes with vocatives, also only ensuring single list  aswell\n",
    "\n",
    "    correct_database = []\n",
    "\n",
    "    for i in book_real.index:\n",
    "\n",
    "        if type(book_real.at[i,'addressee']) == list:\n",
    "\n",
    "            if len(book_real.at[i,'addressee']) == 1:\n",
    "\n",
    "                new_row = book_real.loc[i]\n",
    "\n",
    "                new_row.at['addressee'] = new_row.at['addressee'][0] # making single element a list\n",
    "\n",
    "                correct_database.append(new_row)\n",
    "                \n",
    "            else: \n",
    "                \n",
    "                new_row = book_real.loc[i]\n",
    "\n",
    "                new_row.at['addressee'] = np.nan # not trying to predict this row\n",
    "\n",
    "                correct_database.append(new_row)\n",
    "\n",
    "        else:\n",
    "    \n",
    "            correct_database.append(book_real.loc[i])\n",
    "    \n",
    "    correct_database = pd.DataFrame(correct_database)\n",
    "\n",
    "\n",
    "    book_predicted_dialogue = correct_database[correct_database['dialogue'] != 'NO QUOTE']\n",
    "\n",
    "\n",
    "    correct_database = []\n",
    "\n",
    "    for i in book_predicted_BL.index:\n",
    "\n",
    "        if type(book_predicted_BL.at[i,'addressee']) == list:\n",
    "\n",
    "            if len(book_predicted_BL.at[i,'addressee']) == 1:\n",
    "\n",
    "                new_row = book_predicted_BL.loc[i]\n",
    "\n",
    "                new_row.at['addressee'] = new_row.at['addressee'][0] # making single element a list\n",
    "\n",
    "                correct_database.append(new_row)\n",
    "                \n",
    "            else: \n",
    "                \n",
    "                new_row = book_predicted_BL.loc[i]\n",
    "\n",
    "                new_row.at['addressee'] = np.nan # not trying to predict this row\n",
    "\n",
    "                correct_database.append(new_row)\n",
    "\n",
    "        else:\n",
    "    \n",
    "            correct_database.append(book_predicted_BL.loc[i])\n",
    "    \n",
    "    correct_database = pd.DataFrame(correct_database)\n",
    "\n",
    "\n",
    "    book_predicted_BL = correct_database[correct_database['dialogue'] != 'NO QUOTE']\n",
    "\n",
    "\n",
    "    for i in book_predicted_dialogue.index:\n",
    "\n",
    "        vocative_present = False # placeholder to say if a vocative was found in the dialogue\n",
    "\n",
    "        for char in range(len(Characters)):\n",
    "\n",
    "            if (book_predicted_ML.at[i,'addressee'] is np.nan) == False:\n",
    "\n",
    "                for alias in Aliases[char]:\n",
    "    \n",
    "                    if (', ' + alias) in book_predicted_dialogue.at[i,'dialogue']:\n",
    "    \n",
    "                        vocative_present = True\n",
    "    \n",
    "                        if Characters[char] == book_predicted_BL.at[i,'addressee']:\n",
    "    \n",
    "                            count_vocative_found_BL += 1\n",
    "    \n",
    "                        if Characters[char] == book_predicted_ML.at[i,'addressee']:\n",
    "    \n",
    "                            count_vocative_found_ML += 1\n",
    "                            \n",
    "                        if Characters[char] == book_predicted_ML_SA.at[i,'addressee']:\n",
    "    \n",
    "                            count_vocative_found_ML_SA += 1\n",
    "    \n",
    "                        \n",
    "    \n",
    "                    elif (alias + ', ') in book_predicted_dialogue.at[i,'dialogue']:\n",
    "    \n",
    "                        vocative_present = True\n",
    "    \n",
    "                        if Characters[char] == book_predicted_BL.at[i,'addressee']:\n",
    "    \n",
    "                            count_vocative_found_BL += 1\n",
    "    \n",
    "                        if Characters[char] == book_predicted_ML.at[i,'addressee']:\n",
    "    \n",
    "                            count_vocative_found_ML += 1\n",
    "                            \n",
    "                        if Characters[char] == book_predicted_ML_SA.at[i,'addressee']:\n",
    "    \n",
    "                            count_vocative_found_ML_SA += 1\n",
    "    \n",
    "        if vocative_present == True:\n",
    "\n",
    "            count_vocative += 1\n",
    "\n",
    "        count_quotes += 1\n",
    "\n",
    "\n",
    "vocative_accuracy_BL = count_vocative_found_BL / count_vocative\n",
    "vocative_accuracy_ML = count_vocative_found_ML / count_vocative\n",
    "vocative_accuracy_ML_SA = count_vocative_found_ML_SA / count_vocative\n",
    "\n",
    "\n",
    "vocative_prop = count_vocative / count_quotes\n",
    "\n",
    "\n",
    "with open('Tables/vocative_performance.csv','w') as file:\n",
    "\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    writer.writerows([['model','vocative_accuracy'],['baseline',vocative_accuracy_BL],['ML',vocative_accuracy_ML],['ML_SA',vocative_accuracy_ML_SA]])\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b76b741a-5f9b-4e83-96c8-1bce80a0334e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average Correct Speaker Probability 0.45268111601385497\n",
      " Average False Speaker Probability 0.14349159715434032\n",
      " Average Correct Addressee Probability 0.3403095911190253\n",
      " Average False Addressee Probability 0.038299426264864905\n",
      " Average Correct Exp Probability 0.8847554262663075\n",
      " Average False Exp Probability 0.006575255892738235\n",
      " Average Correct Ana Probability 0.41846685447796916\n",
      " Average False Ana Probability 0.17792751518159217\n",
      " Average Correct Imp Probability 0.20242218734061004\n",
      " Average False Imp Probability 0.23893164239922854\n"
     ]
    }
   ],
   "source": [
    "# Looking at the top-ranking probabilities that were used to assign speakers and addressees,\n",
    "# and their impact on results\n",
    "\n",
    "for book_name in Novel_names:\n",
    "\n",
    "    book_correct = pd.read_csv('Annotated_New/'+book_name + 'anotatednew.csv')\n",
    "    \n",
    "    book_ML = pd.read_csv('predicted_books/ML_Full/'+book_name+'MLFullpredicted.csv')\n",
    "    \n",
    "    prob_correct_sp_exp = 0\n",
    "    prob_false_sp_exp = 0\n",
    "    count_sp_exp = 0\n",
    "    \n",
    "    prob_correct_sp_ana = 0\n",
    "    prob_false_sp_ana = 0\n",
    "    count_sp_ana = 0\n",
    "    \n",
    "    prob_correct_sp_imp = 0\n",
    "    prob_false_sp_imp = 0\n",
    "    count_sp_imp = 0\n",
    "    \n",
    "    prob_correct_ad = 0\n",
    "    prob_false_ad = 0\n",
    "    count_ad = 0\n",
    "    \n",
    "    \n",
    "    for i in book_correct.index:\n",
    "    \n",
    "        if book_correct.at[i,'dialogue'] != 'NO QUOTE':\n",
    "    \n",
    "            if book_correct.at[i,'speaker'] == book_ML.at[i,'speaker']:\n",
    "    \n",
    "                prob_correct_sp += book_ML.at[i,'probability_sp']\n",
    "                count_sp += 1\n",
    "    \n",
    "            else:\n",
    "    \n",
    "                prob_false_sp += book_ML.at[i,'probability_sp']\n",
    "                count_sp += 1\n",
    "    \n",
    "            if book_correct.at[i,'addressee'] == book_ML.at[i,'addressee']:\n",
    "    \n",
    "                prob_correct_ad += book_ML.at[i,'probability_ad']\n",
    "                count_ad += 1\n",
    "    \n",
    "            else:\n",
    "    \n",
    "                if (book_correct.at[i,'addressee'] is np.nan) == False:\n",
    "    \n",
    "                    prob_false_ad += book_ML.at[i,'probability_ad']\n",
    "                    count_ad += 1\n",
    "    \n",
    "            if book_correct.at[i,'syntactic'] == 'Explicit':\n",
    "    \n",
    "                if book_correct.at[i,'speaker'] == book_ML.at[i,'speaker']:\n",
    "    \n",
    "                    prob_correct_sp_exp += book_ML.at[i,'probability_sp']\n",
    "                    count_sp_exp += 1\n",
    "    \n",
    "                else:\n",
    "    \n",
    "                    prob_false_sp_exp += book_ML.at[i,'probability_sp']\n",
    "                    count_sp_exp += 1\n",
    "                    \n",
    "            if book_correct.at[i,'syntactic'] == 'Anaphoric':\n",
    "    \n",
    "                if book_correct.at[i,'speaker'] == book_ML.at[i,'speaker']:\n",
    "    \n",
    "                    prob_correct_sp_ana += book_ML.at[i,'probability_sp']\n",
    "                    count_sp_ana += 1\n",
    "    \n",
    "                else:\n",
    "    \n",
    "                    prob_false_sp_ana += book_ML.at[i,'probability_sp']\n",
    "                    count_sp_ana += 1\n",
    "    \n",
    "            if book_correct.at[i,'syntactic'] == 'Implicit':\n",
    "    \n",
    "                if book_correct.at[i,'speaker'] == book_ML.at[i,'speaker']:\n",
    "    \n",
    "                    prob_correct_sp_imp += book_ML.at[i,'probability_sp']\n",
    "                    count_sp_imp += 1\n",
    "    \n",
    "                else:\n",
    "    \n",
    "                    prob_false_sp_imp += book_ML.at[i,'probability_sp']\n",
    "                    count_sp_imp += 1\n",
    "    \n",
    "            \n",
    "                \n",
    "\n",
    "\n",
    "print(f' Average Correct Speaker Probability {prob_correct_sp/count_sp}')\n",
    "print(f' Average False Speaker Probability {prob_false_sp/count_sp}')\n",
    "\n",
    "print(f' Average Correct Addressee Probability {prob_correct_ad/count_ad}')\n",
    "print(f' Average False Addressee Probability {prob_false_ad/count_ad}')\n",
    "\n",
    "print(f' Average Correct Exp Probability {prob_correct_sp_exp/count_sp_exp}')\n",
    "print(f' Average False Exp Probability {prob_false_sp_exp/count_sp_exp}')\n",
    "\n",
    "print(f' Average Correct Ana Probability {prob_correct_sp_ana/count_sp_ana}')\n",
    "print(f' Average False Ana Probability {prob_false_sp_ana/count_sp_ana}')\n",
    "\n",
    "print(f' Average Correct Imp Probability {prob_correct_sp_imp/count_sp_imp}')\n",
    "print(f' Average False Imp Probability {prob_false_sp_imp/count_sp_imp}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
